{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f0ade662",
   "metadata": {},
   "source": [
    "# Python Files:\n",
    "## 1. Capturing Spatial Points of Object\n",
    "#### Press 1, 2, 3 and 4 number buttons to capture depth images and store their respective array of spatial points.\n",
    "#### This program stores numpy array of spatial points in \"/spatial-points\" \n",
    "#### and stores depth maps in \"/depth-images\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34e5d8a9",
   "metadata": {},
   "source": [
    "### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "735f34d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import depthai as dai\n",
    "import time\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73216616",
   "metadata": {},
   "source": [
    "### Global Parameters\n",
    "#### These parameters are used to define boundary to the ROI and also decides the step between each ROI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "214b4091",
   "metadata": {},
   "outputs": [],
   "source": [
    "extremeLeft = dai.Point2f(0.3, 0.1)\n",
    "extremeRight = dai.Point2f(0.7, 0.9)\n",
    "stepX = 50\n",
    "stepY = 50\n",
    "stepSizeX = (extremeRight.x - extremeLeft.x) / stepX\n",
    "stepSizeY = (extremeRight.y - extremeLeft.y) / stepY"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72fc2b5f",
   "metadata": {},
   "source": [
    "### Pipeline and Nodes Declaration \n",
    "#### \"pipeline\" is the main pipeline which is uploaded to OAK-D\n",
    "#### \"monoLeft\" and \"monoRight\" nodes are Mono Camera nodes which are used for depth imaging.\n",
    "#### \"stereo\" node calculates disparity and depth from both mono camera's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1b0d9f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create pipeline\n",
    "pipeline = dai.Pipeline()\n",
    "\n",
    "# Define sources and outputs\n",
    "# Nodes\n",
    "monoLeft = pipeline.create(dai.node.MonoCamera)\n",
    "monoRight = pipeline.create(dai.node.MonoCamera)\n",
    "stereo = pipeline.create(dai.node.StereoDepth)\n",
    "spatialLocationCalculator = pipeline.create(dai.node.SpatialLocationCalculator)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "023d9612",
   "metadata": {},
   "source": [
    "### Links and config\n",
    "#### Links are data lines connections between nodes\n",
    "#### xin and xout are input and output links respectively\n",
    "#### Stream name is the queue name of link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c378cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Links\n",
    "xoutDepth = pipeline.create(dai.node.XLinkOut)\n",
    "xoutSpatialData = pipeline.create(dai.node.XLinkOut)\n",
    "xinSpatialCalcConfig = pipeline.create(dai.node.XLinkIn)\n",
    "\n",
    "#Links Config\n",
    "xoutDepth.setStreamName(\"depth\")\n",
    "xoutSpatialData.setStreamName(\"spatialData\")\n",
    "xinSpatialCalcConfig.setStreamName(\"spatialCalcConfig\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49fd53b2",
   "metadata": {},
   "source": [
    "### Nodes Properties Declarations\n",
    "#### Setting properties and configuring stereo and monoCam nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f196269e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Properties\n",
    "monoLeft.setResolution(dai.MonoCameraProperties.SensorResolution.THE_400_P)\n",
    "monoLeft.setBoardSocket(dai.CameraBoardSocket.LEFT)\n",
    "monoRight.setResolution(dai.MonoCameraProperties.SensorResolution.THE_400_P)\n",
    "monoRight.setBoardSocket(dai.CameraBoardSocket.RIGHT)\n",
    "\n",
    "lrcheck = False\n",
    "subpixel = False\n",
    "\n",
    "stereo.initialConfig.setConfidenceThreshold(255)\n",
    "stereo.setLeftRightCheck(lrcheck)\n",
    "stereo.setSubpixel(subpixel)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40ed5c40",
   "metadata": {},
   "source": [
    "### Configuration and Linking\n",
    "#### Spatial Node configurations\n",
    "#### topLeft and bottomRight are extreme points of ROI\n",
    "#### stepSize is step of ROI to loop in whole frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07cac871",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Config\n",
    "# Initial ROI box\n",
    "topLeft = dai.Point2f((extremeLeft.x), (extremeLeft.y))\n",
    "bottomRight = dai.Point2f((extremeLeft.x + stepSizeX), (extremeLeft.y + stepSizeY))\n",
    "\n",
    "config = dai.SpatialLocationCalculatorConfigData()\n",
    "config.depthThresholds.lowerThreshold = 100\n",
    "config.depthThresholds.upperThreshold = 10000\n",
    "config.roi = dai.Rect(topLeft, bottomRight)\n",
    "\n",
    "spatialLocationCalculator.setWaitForConfigInput(False)\n",
    "spatialLocationCalculator.initialConfig.addROI(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd9a8919",
   "metadata": {},
   "source": [
    "### Linking nodes and links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c7fb525",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linking\n",
    "monoLeft.out.link(stereo.left)\n",
    "monoRight.out.link(stereo.right)\n",
    "\n",
    "spatialLocationCalculator.passthroughDepth.link(xoutDepth.input)\n",
    "stereo.depth.link(spatialLocationCalculator.inputDepth)\n",
    "\n",
    "spatialLocationCalculator.out.link(xoutSpatialData.input)\n",
    "xinSpatialCalcConfig.out.link(spatialLocationCalculator.inputConfig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e760b6be",
   "metadata": {},
   "source": [
    "### Core Program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bb742f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "with dai.Device(pipeline) as device:\n",
    "    points=[]\n",
    "    # Output queue will be used to get the depth frames from the outputs defined above\n",
    "    depthQueue = device.getOutputQueue(name=\"depth\", maxSize=4, blocking=False)\n",
    "    spatialCalcQueue = device.getOutputQueue(name=\"spatialData\", maxSize=4, blocking=False)\n",
    "    spatialCalcConfigInQueue = device.getInputQueue(\"spatialCalcConfig\")\n",
    "    color = (255, 255, 255)\n",
    "    print(\"\\n Program Running.\")\n",
    "    while(True):\n",
    "        inDepth = depthQueue.get() # Blocking call, will wait until a new data has arrived\n",
    "        depthFrame = inDepth.getFrame()\n",
    "        depthFrameColor = cv2.normalize(depthFrame, None, 255, 0, cv2.NORM_INF, cv2.CV_8UC1)\n",
    "        depthFrameColor = cv2.equalizeHist(depthFrameColor)\n",
    "        depthFrameColor = cv2.applyColorMap(depthFrameColor, cv2.COLORMAP_HOT)\n",
    "        cv2.imshow(\"Depth\",depthFrameColor)\n",
    "        key = cv2.waitKey(1)\n",
    "        if key == ord('1') or key == ord('2') or key == ord('3') or key == ord('4') :\n",
    "            print(f\"\\n{chr(key)} Caputring process started.\")\n",
    "            #time.sleep(3)\n",
    "            for _ in range(stepX):\n",
    "                for _ in range(stepY):\n",
    "                    config.roi = dai.Rect(topLeft, bottomRight)\n",
    "                    config.calculationAlgorithm = dai.SpatialLocationCalculatorAlgorithm.AVERAGE\n",
    "                    cfg = dai.SpatialLocationCalculatorConfig()\n",
    "                    cfg.addROI(config)\n",
    "                    spatialCalcConfigInQueue.send(cfg)\n",
    "                    spatialData = spatialCalcQueue.get().getSpatialLocations()\n",
    "                    for depthData in spatialData:\n",
    "                        # roi = depthData.config.roi\n",
    "                        # roi = roi.denormalize(width=depthFrameColor.shape[1], height=depthFrameColor.shape[0])\n",
    "                        # xmin = int(roi.topLeft().x)\n",
    "                        # ymin = int(roi.topLeft().y)\n",
    "                        # xmax = int(roi.bottomRight().x)\n",
    "                        # ymax = int(roi.bottomRight().y)\n",
    "                        # depthMin = depthData.depthMin\n",
    "                        # depthMax = depthData.depthMax\n",
    "                        # fontType = cv2.FONT_HERSHEY_TRIPLEX\n",
    "                        # cv2.rectangle(depthFrameColor, (xmin, ymin), (xmax, ymax), color, cv2.FONT_HERSHEY_SCRIPT_SIMPLEX)\n",
    "                        points.append([depthData.spatialCoordinates.x, depthData.spatialCoordinates.y,\n",
    "                                       depthData.spatialCoordinates.z])\n",
    "                    topLeft.y += stepSizeY\n",
    "                    bottomRight.y += stepSizeY\n",
    "                topLeft.y = extremeLeft.y\n",
    "                bottomRight.y = topLeft.y + stepSizeY\n",
    "                topLeft.x += stepSizeX\n",
    "                bottomRight.x += stepSizeX\n",
    "            topLeft = dai.Point2f((extremeLeft.x), (extremeLeft.y))\n",
    "            bottomRight = dai.Point2f((extremeLeft.x + stepSizeX), (extremeLeft.y + stepSizeY))\n",
    "            cv2.imwrite(f\"depth-images/{chr(key)}.jpg\", depthFrameColor)\n",
    "            np.save(f\"spatial-points/{chr(key)}.npy\", points)\n",
    "            print(f\"\\n {chr(key)} Captured\")\n",
    "        elif key==ord('q'):\n",
    "            break\n",
    "print(\"\\n Program Completed\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
